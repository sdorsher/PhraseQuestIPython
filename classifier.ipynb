{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import os, sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import cauchy\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(filename,\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def powerlaw(x,a,b,c):\n",
    "    return a*x**b+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f5(x,a,b,c,d,g,h):\n",
    "    return a*x**5+b*x**4+c*x**3+d*x**2+g*x+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f3(x,a,b,c,d):\n",
    "    return a*x**3+b*x**2+c*x+d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VowelToConsRatio(name):\n",
    "    \n",
    "    words = sum(c.isalpha() for c in name)\n",
    "    spaces = sum(c.isspace() for c in name)\n",
    "    others = len(name) - words - spaces\n",
    "    vowels = sum(map(name.lower().count, \"aeiou\"))\n",
    "    consonents = words - vowels\n",
    "\n",
    "\n",
    "    return float(vowels)/float(consonents), float(spaces)/float(consonents), float(others)/float(consonents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AirportNameLetterFrequency(name):\n",
    "    \n",
    "    words = sum(c.isalpha() for c in name)\n",
    "    spaces = sum(c.isspace() for c in name)\n",
    "    others = len(name) - words - spaces\n",
    "    vowels = sum(map(name.lower().count, \"aeiou\"))\n",
    "    consonents = words - vowels\n",
    "    #put a one at the end to account for one airport in number totaled. will be normalized later\n",
    "\n",
    "    return [consonents, vowels, spaces, others, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MergeCount(totalCount, thisCount):\n",
    "    totalCount2=totalCount+thisCount\n",
    "    return totalCount2\n",
    "\n",
    "#def CounttoHistograms(thisUSAcount, totalUSAcount, totalEnglandcount, totalTurkeycount, totalFrancecount, totalGermanycount, totalMexicocount, totalCanadacount)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "totalUSAcount=np.zeros(5)\n",
    "totalChinacount=np.zeros(5)\n",
    "totalEnglandcount=np.zeros(5)\n",
    "totalFrancecount=np.zeros(5)\n",
    "totalGermanycount=np.zeros(5)\n",
    "totalMexicocount=np.zeros(5)\n",
    "totalCanadacount=np.zeros(5)\n",
    "\n",
    "\n",
    "\n",
    "#I picked some countries I have familiarity with so I know whether or not the data makes sense when I see it, sort of.\n",
    "\n",
    "#what I want is the histogram of counts within each country to compare distributions between countries by eye. I can then look at a regression within the US by longitude and lattitude (actual distance from Chicago?) if it looks interesting\n",
    "\n",
    "ratio=[]\n",
    "coords=[]\n",
    "\n",
    "\n",
    "for line in file:\n",
    "    line=re.split(',',line);\n",
    "\n",
    "    if line[3] == \"\\\"China\\\"\":\n",
    "        thisratioV, thisratioS, thisratioO=VowelToConsRatio(line[1]);\n",
    "        ratio.append([thisratioV,thisratioS,thisratioO])\n",
    "        coords.append([float(line[6]),float(line[7])])\n",
    "    if line[3] == \"\\\"United States\\\"\":\n",
    "        thisratioV, thisratioS, thisratioO=VowelToConsRatio(line[1]);\n",
    "        ratio.append([thisratioV,thisratioS,thisratioO])\n",
    "        coords.append([float(line[6]),float(line[7])])\n",
    "    if line[3] == \"\\\"United Kingdom\\\"\":\n",
    "        thisratioV, thisratioS, thisratioO=VowelToConsRatio(line[1]);\n",
    "        ratio.append([thisratioV,thisratioS,thisratioO])\n",
    "        coords.append([float(line[6]),float(line[7])])\n",
    "    if line[3] == \"\\\"France\\\"\":\n",
    "        thisratioV, thisratioS, thisratioO=VowelToConsRatio(line[1]);\n",
    "        ratio.append([thisratioV,thisratioS,thisratioO])\n",
    "        coords.append([float(line[6]),float(line[7])])\n",
    "    \n",
    "    if line[3] == \"\\\"Germany\\\"\":#\n",
    "        thisratioV, thisratioS, thisratioO=VowelToConsRatio(line[1]);\n",
    "        ratio.append([thisratioV,thisratioS,thisratioO])\n",
    "        coords.append([float(line[6]),float(line[7])])\n",
    "    if line[3] == \"\\\"Mexico\\\"\" :\n",
    "        thisratioV, thisratioS, thisratioO=VowelToConsRatio(line[1]);\n",
    "        ratio.append([thisratioV,thisratioS,thisratioO])\n",
    "        coords.append([float(line[6]),float(line[7])])\n",
    "    if line[3] == \"\\\"Canada\\\"\" :\n",
    "        thisratioV, thisratioS, thisratioO=VowelToConsRatio(line[1]);\n",
    "        ratio.append([thisratioV,thisratioS,thisratioO])\n",
    "        coords.append([float(line[6]),float(line[7])])\n",
    "\n",
    "ratioarray=np.asarray(ratio)\n",
    "coordsarray=np.asarray(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5         0.25        0.25      ]\n",
      " [ 0.55555556  0.22222222  0.16666667]]\n"
     ]
    }
   ],
   "source": [
    "print ratioarray[1:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50.0564002991, -97.03250122070001], [44.6397018433, -63.499401092499994]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print coords[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(ratio)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "trainingdat=scaler.transform(ratioarray)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (2730, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-18e1d611add5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'modified_huber'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingdat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#modified_huber loss function (counting values between 0 and 1  to continuous values), using l2 (RSS) error for distance measure. note that this does not make use of power law scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    543\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    524\u001b[0m                         dtype=None)\n\u001b[1;32m    525\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (2730, 2)"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='modified_huber', penalty='l2')\n",
    "clf.fit(trainingdat,coords)\n",
    "#modified_huber loss function (counting values between 0 and 1  to continuous values), using l2 (RSS) error for distance measure. note that this does not make use of power law scaling\n",
    "#doesn't run!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-93ddb0bc55d4>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-93ddb0bc55d4>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    classlabels=clf.predict(trainingdata)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
    "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
    "       shuffle=True, tol=None, verbose=0, warm_start=False\n",
    "\n",
    "classlabels=clf.predict(trainingdata)\n",
    "distance=clf.decision_function(trainingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-83d39e51d380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "print len(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2730, 3)\n"
     ]
    }
   ],
   "source": [
    "print trainingdat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6b696f63c6b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.gca()\n",
    "\n",
    "\n",
    "ax.scatter(trainingdata[:,1],trainingdata[:,0],c=classlabels,cmap=cm.plasma_r)\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Map of classes in language space for seven countries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.gca()\n",
    "\n",
    "ax.scatter(coords[:,1],coords[:,0],c=classlabels,cmap=cm.plasma_r)\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('World map of language classes for seven countries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.gca()\n",
    "\n",
    "\n",
    "ax.scatter(coords[:,1],coords[:,0],c=distance,cmap=cm.plasma_r)\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('World map of distances from the centers of language classes')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
